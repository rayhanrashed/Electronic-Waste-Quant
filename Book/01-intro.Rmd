# Can We Dig Further?? {#intro}


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```
```{r, echo=FALSE}


packages <- c("ggplot2","plyr", "dplyr", "multcomp","MASS","knitr","DiagrammeR","effects","caret","boot","car")


suppressWarnings(librarian::shelf(packages,quiet = TRUE))


mutation_df <- function(df) {
  #library(plyr)
  df$device_count_5_yr <- factor(
    df$device_count_5_yr
    ,
    levels = c("0", "1-2",
               "3-4", "4-6",
               "6-8", "8-10",
               "10-12", "12-")
  )
  #df$device_count_5_yr <- as.ordered(df$device_count_5_yr)
  mapvalues(df$device_count_5_yr,
            from = c("0", "1-2","3-4", "4-6","6-8", "8-10","10-12", "12-"),
            to = c("0", "2","4", "6","8", "10","12", "14")
            )
  
  df$device_count_5_yr <- as.numeric(df$device_count_5_yr)
  df$device_count_5_yr <- df$device_count_5_yr*2 -2  
  df$last_dumped_device <- relevel(df$last_dumped_device, "Smartphone")
  
  df$dump_within <- factor(df$dump_within,
                           levels = c("<1 mn", "<6 mn", "<1 yr", "<2 yr", "<4 yr", ">4 yr"))
  df$age <- as.ordered(df$age)
  df$dump_within <- as.ordered(df$dump_within)
  df$miss_another <- sub("N ", "N", df$miss_another)
  df$edu <- factor(df$edu,
                   levels = c("SSC","High School", "Bachelors","Masters","PhD"))
  df$edu <- factor(df$edu)
  
  
  #########checking-improving stepwise
  df$did_with_data_Y[df$did_with_data<=2]<-0 
  df$did_with_data_Y[df$did_with_data>=3]<-1
  df$did_with_device_econ[df$did_with_device<=2]<-1
  df$did_with_device_econ[df$did_with_device>=3]<-0
  #df$did_with_data <- factor()
  
  df$did_with_data_Y <- as.factor(df$did_with_data_Y)
  df$did_with_device_econ <- as.factor(df$did_with_device_econ)
  df <- dplyr::select(df,-c(did_with_data,did_with_device,X))
  
  # df$memory_dev[df$memory_dev=="N"] <- 0 
  # df$memory_dev[df$memory_dev=="Y"] <- 1
  # df$miss_another[df$miss_another=="N"] <- 0 
  # df$miss_another[df$miss_another=="Y"] <- 1
  levels(df$memory_dev) <- c(0,1)
  levels(df$miss_another) <- c(0,1)
  levels(df$miss_dev) <- c(0,1)
  
  df$bad_rep_exp <- relevel(df$bad_rep_exp,ref = "NC")
  #df$will_dev_rec[df$will_dev_rec==""] <- "NC"
  #df$will_dev_rec <- factor(df$will_dev_rec)
  df$will_dev_rec <- relevel(df$will_dev_rec,ref = "NC")
  
  #df$repair_try <- 1
  df$repair_try[df$self_try_No==1] <- 0
  df$repair_try[df$self_try_No==0] <- 1
  df$repair_try <- as.factor(df$repair_try)
  
  df$repair_succ[df$self_try_Success==1] <- 1
  df$repair_succ[df$self_try_Success==0] <- 0
  df$repair_succ <- as.factor(df$repair_succ)
  
  df$self_rep_combined[df$self_try_Success==1] <- "S"
  df$self_rep_combined[df$self_try_Failed==1] <- "F"
  df$self_rep_combined[df$self_try_No==1] <- "N"
  df$self_rep_combined <- factor(df$self_rep_combined)
  df$self_rep_combined <- relevel(df$self_rep_combined,"N")

  for (i in 11:44) {
    df[,i] <- as.factor(df[,i])
  }
  
  for (i in 46:51) {
    df[,i] <- as.factor(df[,i])
  }
  
 return(df)
}

create_code <- function(df) {
#  df$division.sum <- df$division
  contrasts(df$division) <- contr.sum(length(unique(df$division)))
  
  #df$age.sum <- df$age
  contrasts(df$age) <- contr.sum(length(unique(df$age)))
  contrasts(df$age) <- contr.sum(length(unique(df$age)))
  contrasts(df$last_dumped_device) <- contr.sum(length(unique(df$last_dumped_device)))
  contrasts(df$dump_within) <- contr.helmert(length(unique(df$dump_within)))
  
  return(df)
}

pack <- function(filename) {
  setwd("/Users/MBP/Documents/ElectronicWaste/")
  df=read.csv(filename,stringsAsFactors = T)
  #df=read.csv("temp.csv",stringsAsFactors = T)
  df <- mutation_df(df)
  #df <- rename_df(df)
  df <- create_code(df)
  return(df)
}

Generate_RoC <- function(full_model,null_model,df,outcome,direction) {
  library(ROCR)
  librarian::shelf(pROC,quiet = T)
  n <- nrow(df)
  print(n)
  trainingidx <- sample(1:n, 0.9 * n)
  train <- df[trainingidx,]
  test <- df[-trainingidx,]
  step_model <- NULL
  if (direction=="F") {
    step_model <- step(null_model, scope = list(lower = null_model, upper = full_model), direction = "forward", trace = FALSE)
    #print(step_model %>% summary())
    test$pred <- predict(step_model,test,type="response")
    test$real <- test[,outcome]
    
    train$pred <- predict(step_model,train,type="response")
    train$real <- train[,outcome]
    
  }
  else{
    step_model <-step(full.model,direction = "backward",trace = 0)
    #print(step_model %>% summary())
    
    test$pred <- predict(step_model,test,type="response")
    test$real <- test[,outcome]
    
    train$pred <- predict(step_model,train,type="response")
    train$real <- train[,outcome]
  }
  

  
  
  plot.roc(test$real,test$pred, col = "red", main="ROC Validation set",
           percent = TRUE, print.auc = TRUE)
  

}


```

```{r include=FALSE}
#temp <- pack("temp.csv")
filename="temp.csv"
#filename="missing_regression.csv"
df <- pack(filename)

attach(df)

suppressWarnings( full.model<- glm(miss_dev ~ (dump_within + did_with_device_econ + 
      memory_dev + dump_reason_break + dump_reason_theft + dump_reason_slow)^2, 
    family = binomial, data = df))
#full.model %>% summary()
```

We have introduced All Pairwise Interactions Here *from the best fitted model of Chapter 1*. Lets see how many survives upon the finishing of ***Backward Stepwise Regression Model***

```{r}
suppressWarnings( backward.model <- step(full.model,direction = "backward",trace = 0))

backward.model %>% summary()





```



The AIC Value was Initially 477.


*After Stepwise Regression, it came down to 437*


***After Adding the Interaction elements, it is now*** 
`r extractAIC(backward.model)[2] `

The 10 fold cross validation accuracy is below:
```{r message=FALSE}
suppressWarnings( cross_validated_model <- boot::cv.glm(df,glmfit = backward.model,K = 10))
print((1-cross_validated_model$delta[1])*100)

```
Lets also look at the ROC curve for the the fitted logistic regression model: ***(A better fit than model without interaction)***

```{r message=FALSE}
null.model <- glm(miss_dev~1,family = binomial(),data = df)
suppressWarnings( Generate_RoC(full_model = full.model,null_model = null.model,df = df,direction = "B",outcome = "miss_dev"))

```
With a good fit in the model, lets diagnosis our model parameters for multicolineariy. If the ***VIF*** (Variance Inflation Factor) is $>10$ for any predictor, we might be in trouble.

```{r message=FALSE}
cat("MIN IVF: ",min(vif(backward.model)))
cat("MAX IVF: ",max(vif(backward.model)))
cat("MEAN IVF: ",mean(vif(backward.model)))
        
```


Lets look at the effects plot to better understand the individual effects of each predictor:
```{r}
for (n in c(
  "dump_within"
  ,"did_with_device_econ"
  ,"memory_dev"
  ,"dump_reason_break"
  ,"dump_reason_theft"
  ,"dump_reason_slow"
  # ,"slt_lack_parts"
  # ,"slt_lack_repairer"
  # ,"rprd_usage_chlng_fault"
  # ,"rpr_missing_trait_trust"
  # ,"rpr_missing_trait_gender"
  # ,"dev_tknto_rec_Y"
  # ,"dev_rec_chlng_hard_find"
)){
  #print(n)
  print(plot(effects::predictorEffect(n,backward.model)))
}
```
***Adding Interaction introduces Multicolinearity among variables and makes the model unstable. We should not do that for this model. Lets go to chapter 3????***